# ğŸ©º Medinova â€“ AI-Powered Medical Assistant

Medinova is an AI-powered healthcare assistant that combines **speech recognition**, **document understanding**, and **conversational AI** to deliver context-aware, retrieval-augmented responses.  
It supports real-time voice input, PDF/DOCX knowledge ingestion, and persistent memory for long-term patient interaction.

---

## ğŸš€ Features

- **Speech-to-Text (ASR)** â€“ Real-time and file-based transcription using `faster-whisper`.
- **Document Understanding** â€“ Upload PDF/DOCX files, automatically extract and process content.
- **RAG (Retrieval-Augmented Generation)** â€“ FAISS-powered vector search to retrieve relevant context for responses.
- **Conversational Memory** â€“ Persistent memory across sessions using Redis.
- **LLM Integration** â€“ Powered by locally hosted models via Ollama (`medllama2` by default).
- **Graph-Based Orchestration** â€“ Modular chatbot flow using LangGraph.
- **Frontend Interface** â€“ Simple HTML/JS frontend for interaction.

---

## ğŸ›  Tech Stack

**Backend**  
- FastAPI â€“ REST & WebSocket API
- LangGraph + LangChain Core â€“ Agent orchestration
- Ollama â€“ Local LLM API
- FAISS â€“ Vector database
- Redis â€“ Conversation memory
- faster-whisper â€“ Speech recognition
- SentenceTransformers â€“ Text embeddings

**Frontend**  
- HTML, CSS, JavaScript

**Utilities**  
- PyMuPDF (fitz) & python-docx â€“ Document parsing
- NumPy, SoundFile â€“ Audio processing
- Requests â€“ API calls

---

## ğŸ“‚ Project Structure

```
Medinova/
â”‚
â”œâ”€â”€ app.py                     # FastAPI backend entry point
â”œâ”€â”€ requirements.txt           # Dependencies
â”œâ”€â”€ agents/
â”‚   â””â”€â”€ graph_builder.py       # LangGraph-based chatbot logic
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ asr.py                 # Speech-to-text processing
â”‚   â”œâ”€â”€ document_loader.py     # PDF/DOCX loading & parsing
â”‚   â”œâ”€â”€ llm_ollama.py          # Ollama API integration
â”‚   â”œâ”€â”€ memory_store.py        # Redis-based conversation memory
â”‚   â””â”€â”€ vector_store.py        # FAISS vector storage
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ app.js                 # Frontend JavaScript
â”‚   â”œâ”€â”€ index.html             # UI
â”‚   â””â”€â”€ styles.css             # Styling
â””â”€â”€ .gitignore
```

---

## âš™ï¸ Installation

### 1ï¸âƒ£ Clone the repository
```bash
git clone https://github.com/Anjalii-Patel/Medinova.git
cd Medinova
```

### 2ï¸âƒ£ Install dependencies
```bash
pip install -r requirements.txt
```

### 3ï¸âƒ£ Start Redis
Make sure Redis is running locally:
```bash
redis-server
```

### 4ï¸âƒ£ Start Ollama
Install [Ollama](https://ollama.ai) and pull the model:
```bash
ollama pull medllama2
ollama run medllama2
```

### 5ï¸âƒ£ Run the backend
```bash
uvicorn app:app --reload
```

### 6ï¸âƒ£ Open the frontend
Open `frontend/index.html` in your browser.

---

## ğŸ“¡ API Endpoints

### **Upload Document**
```http
POST /upload
```
Uploads and processes PDF/DOCX for RAG.

### **Transcribe Audio**
```http
POST /transcribe
```
Converts audio files to text.

### **WebSocket Chat**
```
/ws/{session_id}
```
Handles real-time chat with memory.

---

## ğŸ“ Architecture

```plaintext
Frontend (HTML/JS)  â†’  FastAPI Backend  â†’  LangGraph Orchestrator
      â†‘                       â†“
   WebSocket             Ollama LLM
                          â†‘     â†“
                    FAISS Vector Store â† Embeddings â† Documents / Audio
                          â†‘
                       Redis Memory
```

---

## ğŸ§ª Example Use Case

1. Upload a **patient report PDF**.
2. Speak to the assistant via **microphone**.
3. Medinova retrieves relevant medical history from FAISS.
4. Generates an **AI-powered response** using local LLM.

---

## ğŸ¤ Contributing

1. Fork this repo.
2. Create a new branch:
```bash
git checkout -b feature-name
```
3. Commit changes and push.
4. Open a Pull Request.

---

## ğŸ“œ License
This project is licensed under the MIT License â€“ see the [LICENSE](LICENSE) file for details.

---
